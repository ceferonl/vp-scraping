---
title: "Scraper Demo"
format: html
jupyter: python3
---

# Scraper Demo: Crawl4AI + Polars

```{python}
import sys, os
sys.path.insert(0, os.path.abspath("src"))
```

This document demonstrates the scraping pipeline for a few sample URLs using the project modules.

## 1. Extract Content URLs

```{python}
from url_extractor import extract_content_urls
urls = extract_content_urls("https://www.versnellingsplan.nl/kennisbank/")
print(f"Found {len(urls)} URLs:")
for url in urls[:3]:
    print(url)
```

## 2. Scrape Content for a Sample URL

```{python}
from content_scraper import scrape_content
sample_url = urls[0] if urls else "https://www.versnellingsplan.nl/kennisbank/some-article"
content = scrape_content(sample_url)
print(content)
```

## 3. Download PDFs for the Sample URL

```{python}
from pdf_downloader import download_pdfs
pdfs = download_pdfs(content.get('pdf_links', []), "output/demo/pdfs")
print(pdfs)
```

## 4. Generate JSON Output

```{python}
from json_generator import generate_json
json_path = generate_json(content, pdfs, "output/demo")
print(f"JSON saved at: {json_path}")
```

---

This demo shows the end-to-end workflow for scraping, PDF downloading, and JSON output using Crawl4AI and project modules.
